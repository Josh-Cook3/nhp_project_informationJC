---
title: "Glossary and definitions"
order: 1
---

This page clarifies the terminology that is used throughout the model and its associated apps.

## Bed days

Bed days are defined as `discharge_date - admission_date + 1`.

## Prediction intervals

A prediction interval (PI) is an interval which is expected to typically contain the variable being estimated. In the context of the NHP Demand and Capacity model, we show results in terms of a principal projection, as well as 90% (upper) and 10% (lower) prediction intervals showing the range of possibilities in the modelled future. For example, if the model's principal projection for beddays is 200,000 and the upper and lower prediction intervals are 210,000 and 190,000, then this indicates the actual number of beddays in the horizon year should lie between this interval with probability 0.8.

On the 'Distribution of projections' section of the outputs app, we have the tabs 'activity summary' (a summary table) and 'activity distribution' (contains the S-curve). Summing the values for the upper and lower prediction intervals on the summary table can give different results to the numbers seen on the S-curve chart for the upper and lower prediction intervals. 

The reason for this is that the summary table calculates the lower and upper values separately for each point of delivery (POD), which means you’re effectively taking a summary of a summary by adding these values together. This contrasts with calculating the lower and upper for all inpatient Point of Deliveries (PODs) together, where all the data is used to generate the summary values and information is not 'lost'. In other words, we can expect the two types of calculation to yield slightly different results.

::: {.callout-note collapse="true"}
## A worked example

Consider this table, which has dummy PODs (A, B and C) and calculates a sum total per row:

|     A        |     B        |     C        |      Total       |
|--------------|--------------|--------------|------------------|
|     20       |     58       |     148      |     226          |
|     16       |     59       |     148      |     223          |
|     11       |     52       |     174      |     237          |
|     17       |     52       |     142      |     211          |
|     12       |     66       |     101      |     179          |
|     7        |     60       |     192      |     259          |
|     17       |     65       |     196      |     278          |
|     14       |     68       |     188      |     270          |
|     12       |     66       |     103      |     181          |
|     15       |     54       |     159      |     228          |
|     8        |     65       |     114      |     187          |
|     8        |     62       |     130      |     200          |
|     10       |     68       |     196      |     274          |
|     7        |     58       |     135      |     200          |
|     13       |     59       |     122      |     194          |
|     5        |     65       |     153      |     223          |
|     14       |     68       |     142      |     224          |
|     16       |     67       |     109      |     192          |
|     14       |     64       |     135      |     213          |
|     10       |     70       |     143      |     223          |
|     20       |     63       |     184      |     267          |

: Table 1

If you take the 10th and 90th percentiles within each of the columns in the above table, you get these values:

|     Centile    |     A     |     B     |     C      |     Total    |
|----------------|-----------|-----------|------------|--------------|
|     10th       |     7     |     54    |     109    |     187      |
|     90th       |     17    |     68    |     192    |     270      |

: Table 2

So the percentile values for Table 1's "Total" column are 187 and 270. But if you simply add up the A, B and C values calculated in Table 2, then you get totals of 170 and 277.

:::

## Distribution of projections

The results of the (usually 256) Monte Carlo simulation runs, each of which will randomly sample from the 80% prediction intervals supplied as the model parameters. The "central projection" is the median result from the 256 runs.  

## Empirical Cumulative Distribution Function (ECDF) Curve / S-Curve

The s-curve shows the range of results (or values) obtained from all the model runs on the x-axis and their likelihood of occurring as (cumulative) percentages (0% to 100%) on the y-axis. There are three main ways of reading the s-curve. 

1. Start from the x-axis. Pick a value from the x-axis (say its 4500) and climb vertically to that point on the s-curve and then read the corresponding y-value - say this is 75%. This means there is a 75% chance that the x-value is less than or equal to 4500. In other words 75% of model runs produced a result of less than or equal to 4500.

2. Start from the y-axis. Pick a given percentage chance value from the y-axis and then find the corresponding x-value. For example, if you want what model results that were obtained 85% of the time, find 85% on the y-axis and then read the corresponding x-value - say this is 5900. This means that there is a 85% chance that the x-value is less than or equal to 5900.

3. You can also find the surprisingly low and high values from the s-curve by reading across from the two y-axis values - 10% and 90% - to the corresponding two x-values. Say these x-values are 6000 and 7300. This means that there is an 80% (=90%-10%) chance that x values fall between 6000 to 7300.

## Impact of changes 

The waterfall diagram shown on Impact of Changes tab of the outputs dashboard shows the impact of each of the individual components of the model which are increasing or decreasing the amount of activity that the model predicts at the horizon year. These contributions are indicative because it is not possible to attribute a particular healthcare activity to a particular factor.

The model works by considering the effect of all model factors (demographic growth, non demographic growth, activity avoidance, and others) simultaneously. Each has a simple effect on its own as well as giving rise to a compound effect when its effect is combined with all of the other model components. This compounding effect is a real world phenomenon that more simplistic models ignore. Within our model this compound effect is explicitly accounted for and is shown as a separate bar within the waterfall chart.

::: {.callout-note collapse="true"}

### Simple example

To better explain the effect of compounding take as an example demographic growth and non demographic growth. Demographic growth refers to an increase in healthcare activity owing to a change in the size or age/ sex mix of a given population. Non demographic growth refers to the tendency for given members of a population to receive more healthcare over time (because of new technology, patient expectations, and other factors).

Imagine there are 100 individuals in the baseline year, consuming 10 units of healthcare each year (these could be inpatient stays, treatments, A&E attendances, or any other unit represented in the model). Imagine at the horizon year there will be 10% more people because of demographic growth (we will ignore age/ sex mix in this example) and the people will be consuming 10% more units of healthcare because of non demographic growth.
In the baseline year there are 1000 units of healthcare being consumed, 100 individuals consuming 10 each. Considered separately:

* Demographic growth only: 10% more people means 110 people consuming 10 units each, which gives 1100 units of healthcare activity at the horizon (+100)
* Non demographic growth only: 10% non demographic growth means 11 units of healthcare for 100 people, which also gives 1100 units of activity (+100)

This gives +200 if you add both effects together giving 1200 units in total.

However, in actual fact there are 110 people consuming 11 units of healthcare at the horizon year, which gives 1210 units of healthcare at the horizon year (+210) 10 more than seen from just adding the two factors together . There is no “correct” place to attribute this extra 10 units of healthcare. It’s just as much to do with demographic growth as it is with non demographic growth. This extra 10 units arises from their compound effect.

This, of course, is a highly over simplistic example. In fact, the effects of all of the factors (demographic growth, non demographic growth, activity avoidance, and the others) are taken into account simultaneously within the model. There is no specific place to put this activity which occurs as a compound effect between the factors.

For a more detailed explanation please see the following worked example and technical explanation.

:::

::: {.callout-note collapse="true"}
## Model interaction term worked example

Let’s assume in one model run that we have factors *a* and *b* which both impact on the same 1000 rows of activity, with the values 1.2 and 0.9.

The impact of factor *a* in isolation would be an addition of 200 rows, as 1.2 * 1000 = 1200, and 1200-1000 = 200.

The impact of factor *b* in isolation would be a reduction of 100 rows, as 0.9 * 1000 = 900, and 900-1000 = -100.

If we take the two factors in isolation, there would therefore be an addition of 100 rows in total, as 1000 + 200 – 100 = 1100.

In our simplified example model, the two factors are multiplied together and used as the lambda parameter in the Poisson resampling step.

1.2 * 0.9 = 1.08

$$ n_{future} = \sum_{i = 1}^{1000}x_i$$

where

$$ X \sim Pois(1.08)$$

The Poisson sampling is random, and as such will provide slightly different results every time. In one model run, it may return the value 1085, meaning that the number of rows has been decreased by 15 (as a result of both compounding and randomness). This would be an estimate of future activity provided by the model.

There is therefore a difference between the impact of the factors taken in isolation (1100) and the model's results using the compounded factors, with random sampling (1085).

1085 – 1100 = -15.

This difference of -15 cannot be directly explained, as it is attributed to the compounded effect of the two factors together, together with the randomness inherent in the Poisson sampling step. It is this value which is encapsulated in the model interaction term.

:::

::: {.callout-note collapse="true"}
## Detailed technical explanation

The Impact of Changes tab on the outputs app shows the "step counts" from the model results, which are high-level estimates of the number of rows that are added/removed due to each parameter. This is represented in the "waterfall diagram" in the outputs app. It's important to note that these numbers are not exact because of the effect of randomness and compounding, as detailed following.

The waterfall chart shows the impact of the individual factors on projected future activity, if they were to happen in isolation. However, within the model, the factors are all applied to the baseline at the same time, which results in a compound effect. Additionally, due to the random sampling, the values may not always add up exactly. The effect of compounding and the random sampling are shown on the waterfall chart as a "model interaction term".

The "step counts" in the model are created during the phase of the model where we create the factors. When we add a "step" to the model we work out which rows of activity are affected by the step, creating a new column per step with the factors for that row. We then take the weighted mean of each new column to get a scalar value, grouped by point of delivery and site of treatment. 

We take this weighted mean, subtract 1, and multiply by the baseline to get the estimated simple effect of the step in isolation from all other steps. When these simple effects are summed, they do not equal the total effect, as in the model the factors are actually multiplied together and not summed. Therefore, we include a model interaction term to describe the effect of multiplying the factors together as well as the residual from random sampling.

:::


## Inpatient admissions

The way in which these are classified and grouped is defined on [this page](https://connect.strategyunitwm.nhs.uk/nhp/project_information/data_extraction/inpatients.html).

## Outpatient attendances

These are divided into first, follow-up, and procedures. Added together, these 3 equal the total amount of outpatient activity. A single appointment cannot appear in procedures and first, or procedures and follow-up, or first and follow up. The way in which we define these is with the following code: 

```
CASE 
  WHEN SUSHRG NOT LIKE 'WF%' AND SUSHRG NOT LIKE 'U%' THEN 'procedure' 
  WHEN atentype IN ('1', '21') THEN 'first' 
  ELSE 'follow-up'`
```

## Regular day / night attenders

Regular day / night attenders are patients admitted electively, as part of a planned series of regular admissions for an on-going regime of broadly similar treatment and who are discharged the same day. Intermittent dialysis cases and patients on regular chemotherapy/radiotherapy are examples of regular day / night admissions.

They are defined in HES data by their value of `CLASSPAT`, `3` for day attenders and `4` for night attenders.

## Principal projection

The key outputs of the model are estimates of future hospital activity. The principal projection can be thought of as the 'best guess' or most likely estimate based on the parameters set.

For model v2.0 onwards, the principal projection is the average (mean) of all the 256 Monte Carlo simulations which have been run for a scenario. In the outputs, users will see a principal projection figure for all the different types of activity which the model forecasts. This approach to determining the principal projection was adopted in July 2024. It ensures that the principal projection will sit in the middle of the activity distribution (i.e. it will be very close to the 50th percentile or median).

For model versions up to and including v1.2, the principal projection was determined by a single model run which took the midpoint of all the parameter prediction intervals set by the user. However, given the probabilistic nature of the model, we have found that using the average of all the simulations is a more stable method of determining the principal projection.  

This is not to be confused with the ONS principal population projection. 

## Summary by year

This page shows the results of the principal projection model run, with the chosen time profiles applied to show the estimated year-by-year increase in activity over time from the baseline year to the horizon year.
